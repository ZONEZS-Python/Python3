# 12.0.2 中文分词原理以及工具包

比较有代表性的支持分词的 Python 工具包有：
1. jieba
1. THULAC
1. FoolNLTK

<a name="6844bf16"></a>
##### 一、jieba（专用于分词的 Python 库，GitHub：[https://github.com/fxsjy/jieba](https://github.com/fxsjy/jieba)，分词效果较好）
支持三种分词模式：
* 精确模式，试图将句子最精确地切开，适合文本分析；
* 全模式，将句子中所有的可能成词的词语都扫描出来，速度非常快，但是不能解决歧义；
* 搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适用于搜索引擎分词。

另外 jieba 支持繁体分词，支持自定义词典。

其使用的算法是基于统计的分词方法，主要有如下几种：
* 基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图 (DAG)；
* 采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合；
* 对于未登录词，采用了基于汉字成词能力的 HMM 模型，使用了 Viterbi 算法。

<a name="2ceab1ce"></a>
###### 1、精确模式分词
精确模式分词，使用 lcut() 方法，类似 cut() 方法，其参数和 cut() 是一致的，只不过返回结果是列表而不是生成器，默认使用精确模式，代码如下：
```python
import jieba
string = '听司机朋友说，现在中国的交通法是保护弱者，导致很多电动车不看红绿灯横窜马路，当然作为司机礼让行人和电动车也是情理之中，但是现在的情况似乎是：只要出现交通事故另一方是电动车或行人，哪怕是电动车或行人突然违规闯红灯冲出来，轿车没有违规只是避让不及也要负次要责任吗？'
result = jieba.lcut(string)
print(len(result), '/'.join(result))

```
输出：
> 72 听/司机/朋友/说/，/现在/中国/的/交通/法是/保护/弱者/，/导致/很多/电动车/不看/红绿灯/横窜/马路/，/当然/作为/司机/礼让/行人/和/电动车/也/是/情理之中/，/但是/现在/的/情况/似乎/是/：/只要/出现/交通事故/另一方/是/电动车/或/行人/，/哪怕/是/电动车/或/行人/突然/违规/闯红灯/冲/出来/，/轿车/没有/违规/只是/避让/不及/也/要/负/次要/责任/吗/？

可以看到分词效果还是不错的。

<a name="cb40b732"></a>
###### 2、全模式分词
使用全模式分词需要添加 cut_all 参数，将其设置为 True，代码如下：
```python
import jieba
string = '听司机朋友说，现在中国的交通法是保护弱者，导致很多电动车不看红绿灯横窜马路，当然作为司机礼让行人和电动车也是情理之中，但是现在的情况似乎是：只要出现交通事故另一方是电动车或行人，哪怕是电动车或行人突然违规闯红灯冲出来，轿车没有违规只是避让不及也要负次要责任吗？'
result = jieba.lcut(string, cut_all=True)
print(len(result), '/'.join(result))

```
输出：
> 101 听/司机/朋友/说///现在/中国/的/交通/法/是/保护/弱者///导致/很多/电动/电动车/动车/不/看/红绿/红绿灯/绿灯/横/窜/马路///当然/作为/司机/礼让/行人/和/电动/电动车/动车/也/是/情理/情理之中/之中///但是/现在/的/情况/似乎/是///只要/出现/交通/交通事故/通事/事故/另一方/一方/是/电动/电动车/动车/或/行人///哪怕/是/电动/电动车/动车/或/行人/突然/违规/闯红灯/红灯/冲出/出来///轿车/没有/有违/违规/只是/避让/不及/也/要/负/次要/责任/吗//


<a name="afe8e28b"></a>
###### 3、搜索引擎模式分词
使用搜索引擎模式分词需要调用 cut_for_search() 方法，代码如下：
```python
import jieba
string = '听司机朋友说，现在中国的交通法是保护弱者，导致很多电动车不看红绿灯横窜马路，当然作为司机礼让行人和电动车也是情理之中，但是现在的情况似乎是：只要出现交通事故另一方是电动车或行人，哪怕是电动车或行人突然违规闯红灯冲出来，轿车没有违规只是避让不及也要负次要责任吗？'
result = jieba.lcut_for_search(string)
print(len(result), '/'.join(result))

```
输出：
> 89 听/司机/朋友/说/，/现在/中国/的/交通/法是/保护/弱者/，/导致/很多/电动/动车/电动车/不看/红绿/绿灯/红绿灯/横窜/马路/，/当然/作为/司机/礼让/行人/和/电动/动车/电动车/也/是/情理/之中/情理之中/，/但是/现在/的/情况/似乎/是/：/只要/出现/交通/通事/事故/交通事故/一方/另一方/是/电动/动车/电动车/或/行人/，/哪怕/是/电动/动车/电动车/或/行人/突然/违规/红灯/闯红灯/冲/出来/，/轿车/没有/违规/只是/避让/不及/也/要/负/次要/责任/吗/？


<br />另外可以加入自定义词典，如我们想把 日本和服 作为一个整体，可以把它添加到词典中，代码如下：
```python
import jieba
jieba.add_word('电动车不看')
string = '听司机朋友说，现在中国的交通法是保护弱者，导致很多电动车不看红绿灯横窜马路，当然作为司机礼让行人和电动车也是情理之中，但是现在的情况似乎是：只要出现交通事故另一方是电动车或行人，哪怕是电动车或行人突然违规闯红灯冲出来，轿车没有违规只是避让不及也要负次要责任吗？'
result = jieba.lcut(string)
print(len(result), '/'.join(result))

```
输出：
> 71 听/司机/朋友/说/，/现在/中国/的/交通/法是/保护/弱者/，/导致/很多/电动车不看/红绿灯/横窜/马路/，/当然/作为/司机/礼让/行人/和/电动车/也/是/情理之中/，/但是/现在/的/情况/似乎/是/：/只要/出现/交通事故/另一方/是/电动车/或/行人/，/哪怕/是/电动车/或/行人/突然/违规/闯红灯/冲/出来/，/轿车/没有/违规/只是/避让/不及/也/要/负/次要/责任/吗/？

可以看到切分结果中，"电动车不看" 四个字就作为一个整体出现在结果中了，分词数量比精确模式少了一个。

<a name="1bb26ba5"></a>
##### 二、THULAC（THU Lexical Analyzer for Chinese）由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包，GitHub 链接：[https://github.com/thunlp/THULAC-Python](https://github.com/thunlp/THULAC-Python)，具有中文分词和词性标注功能。THULAC具有如下几个特点：
* 能力强。利用集成的目前世界上规模最大的人工分词和词性标注中文语料库（约含5800万字）训练而成，模型标注能力强大。
* 准确率高。该工具包在标准数据集Chinese Treebank（CTB5）上分词的F1值可达97.3％，词性标注的F1值可达到92.9％，与该数据集上最好方法效果相当。
* 速度较快。同时进行分词和词性标注速度为300KB/s，每秒可处理约15万字。只进行分词速度可达到1.3MB/s。

实例效果展示：
```python
import thulac

string = '听司机朋友说，现在中国的交通法是保护弱者，导致很多电动车不看红绿灯横窜马路，当然作为司机礼让行人和电动车也是情理之中，但是现在的情况似乎是：只要出现交通事故另一方是电动车或行人，哪怕是电动车或行人突然违规闯红灯冲出来，轿车没有违规只是避让不及也要负次要责任吗？'
t = thulac.thulac()
result = t.cut(string)
print(result)

```
输出：
> [['听', 'v'], ['司机', 'n'], ['朋友', 'n'], ['说', 'v'], ['，', 'w'], ['现在', 't'], ['中国', 'ns'], ['的', 'u'], ['交通法', 'n'], ['是', 'v'], ['保护', 'v'], ['弱者', 'n'], ['，', 'w'], ['导致', 'v'], ['很多', 'm'], ['电动车', 'n'], ['不', 'd'], ['看', 'v'], ['红绿灯', 'n'], ['横窜', 'v'], ['马路', 'n'], ['，', 'w'], ['当然', 'd'], ['作为', 'v'], ['司机', 'n'], ['礼让', 'v'], ['行人', 'n'], ['和', 'c'], ['电动车', 'n'], ['也', 'd'], ['是', 'v'], ['情理之中', 'id'], ['，', 'w'], ['但是', 'c'], ['现在', 't'], ['的', 'u'], ['情况', 'n'], ['似乎', 'd'], ['是', 'v'], ['：', 'w'], ['只要', 'c'], ['出现', 'v'], ['交通', 'n'], ['事故', 'n'], ['另', 'r'], ['一', 'm'], ['方', 'q'], ['是', 'v'], ['电动车', 'n'], ['或', 'c'], ['行人', 'n'], ['，', 'w'], ['哪', 'r'], ['怕', 'v'], ['是', 'v'], ['电动车', 'n'], ['或', 'c'], ['行人', 'n'], ['突然', 'a'], ['违规', 'v'], ['闯', 'v'], ['红灯', 'n'], ['冲', 'v'], ['出', 'v'], ['来', 'v'], ['，', 'w'], ['轿车', 'n'], ['没有', 'd'], ['违规', 'v'], ['只是', 'd'], ['避让', 'v'], ['不', 'd'], ['及', 'v'], ['也', 'd'], ['要', 'v'], ['负次', 'v'], ['要', 'v'], ['责任', 'n'], ['吗', 'u'], ['？', 'w']]


<a name="6dbd14a3"></a>
##### 三、FoolNLTK 它使用 Bi-LSTM 训练而成，包含分词、词性标注、实体识别等功能，同时支持自定义词典，可以训练自己的模型，可以进行批量处理。
```python
import fool

string = '听司机朋友说，现在中国的交通法是保护弱者，导致很多电动车不看红绿灯横窜马路，当然作为司机礼让行人和电动车也是情理之中，但是现在的情况似乎是：只要出现交通事故另一方是电动车或行人，哪怕是电动车或行人突然违规闯红灯冲出来，轿车没有违规只是避让不及也要负次要责任吗？'
result = fool.cut(string)
print(result)

```
输出：
> [['听', '司机', '朋友', '说', '，', '现在', '中国', '的', '交通法', '是', '保护', '弱者', '，', '导致', '很多', '电动', '车', '不', '看', '红绿灯', '横', '窜', '马路', '，', '当然', '作为', '司机', '礼让', '行人', '和', '电动', '车', '也', '是', '情理之中', '，', '但是', '现在', '的', '情况', '似乎', '是', '：', '只要', '出现', '交通', '事故', '另', '一', '方', '是', '电动', '车', '或', '行人', '，', '哪怕', '是', '电动', '车', '或', '行人', '突然', '违规', '闯', '红灯', '冲', '出来', '，', '轿车', '没有', '违规', '只是', '避', '让', '不及', '也', '要', '负次', '要', '责任', '吗', '？']]


